#!/usr/bin/env python3
"""
FIXED: Generate All Critical Visualization Files for PINN Presentation

This script creates all the essential visualization files from existing data
generated by interactive.py and app.py, plus trained models from main.py.

Usage:
    python generate_presentation_visuals.py
    python generate_presentation_visuals.py --force-regenerate
"""

import os
import sys
import torch
import numpy as np
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
import pandas as pd
import json
import time
import argparse
from typing import Dict, List, Tuple, Optional

# Add backend directory to path
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# Import project modules
try:
    from config import cfg, Config
    from src.model.model import PINN
    CONFIG_AVAILABLE = True
except ImportError as e:
    print(f"Warning: Could not import project modules: {e}")
    CONFIG_AVAILABLE = False
    cfg = None

def setup_output_directory():
    """Create organized output directory for presentation visuals"""
    base_dir = "presentation_visuals"
    subdirs = [
        "training_results",
        "flow_fields", 
        "viscosity_analysis",
        "3d_visualizations",
        "accuracy_analysis",
        "multi_scenario",
        "performance_metrics"
    ]
    
    for subdir in [base_dir] + [os.path.join(base_dir, sd) for sd in subdirs]:
        os.makedirs(subdir, exist_ok=True)
    
    return base_dir

def load_existing_model(model_path):
    """Load existing model if available, handling architecture mismatches"""
    if not os.path.exists(model_path):
        print(f"‚ùå No trained model found at: {model_path}")
        print("Please run 'python main.py' first to train a model")
        return None
        
    if not CONFIG_AVAILABLE:
        print("‚ùå Config not available, cannot load model")
        return None
        
    try:
        print(f"üìÇ Loading existing model from: {model_path}")
        
        # First, try to inspect the checkpoint to understand the architecture
        checkpoint = torch.load(model_path, map_location=cfg.DEVICE)
        
        if 'config' in checkpoint:
            saved_config = checkpoint['config']
            print(f"üìã Found saved model config: {saved_config}")
            
            # Update current config to match saved model
            if 'layers' in saved_config:
                cfg.PINN_LAYERS = saved_config['layers']
            if 'use_fourier_features' in saved_config:
                cfg.USE_FOURIER_FEATURES = saved_config['use_fourier_features']
            if 'use_adaptive_weights' in saved_config:
                cfg.USE_ADAPTIVE_WEIGHTS = saved_config['use_adaptive_weights']
                
            print(f"üîß Updated config to match saved model:")
            print(f"   Architecture: {cfg.PINN_LAYERS}")
            print(f"   Fourier features: {cfg.USE_FOURIER_FEATURES}")
            print(f"   Adaptive weights: {cfg.USE_ADAPTIVE_WEIGHTS}")
        
        # Now try to load with updated config
        model = PINN.load(model_path, cfg)
        
        # Quick performance check
        test_a = model.get_inferred_viscosity_param()
        test_error = abs(test_a - cfg.A_TRUE) / cfg.A_TRUE * 100
        print(f"‚úÖ Model loaded - Parameter error: {test_error:.2f}%")
        
        return model
        
    except Exception as e:
        print(f"‚ùå Could not load model: {e}")
        print("\nüí° This usually happens when:")
        print("   ‚Ä¢ Model was trained with different architecture (advanced features)")
        print("   ‚Ä¢ Model file is corrupted")
        print("   ‚Ä¢ Config mismatch between training and current settings")
        print("\nüîß To fix:")
        print("   ‚Ä¢ Run 'python main.py' to retrain with current config")
        print("   ‚Ä¢ Or check if model was trained with --advanced, --fourier, etc.")
        print("\n‚ö†Ô∏è  3D visualizations will be skipped")
        return None

def find_data_directories():
    """Find all available data directories from interactive.py and app.py"""
    data_sources = {}
    
    # Look for interactive.py results
    results_dir = "backend/results"
    if os.path.exists(results_dir):
        for item in os.listdir(results_dir):
            item_path = os.path.join(results_dir, item)
            if os.path.isdir(item_path) and item.startswith("inference_"):
                # Check if this directory has the expected CSV files
                expected_files = [
                    "inferred_flow_3d_complete.csv",
                    "inferred_viscosity_profile.csv"
                ]
                
                has_files = all(os.path.exists(os.path.join(item_path, f)) for f in expected_files)
                if has_files:
                    data_sources[item] = {
                        'type': 'interactive',
                        'path': item_path
                    }
                    print(f"‚úÖ Found interactive.py data: {item}")
    
    # Look for app.py scenario results
    examples_dir = "backend/results/examples"
    if os.path.exists(examples_dir):
        for item in os.listdir(examples_dir):
            item_path = os.path.join(examples_dir, item)
            if os.path.isdir(item_path) and item.startswith("scenario_"):
                # Look for inference subdirectory or direct CSV files
                inference_subdir = os.path.join(item_path, f"inference_{item}")
                if os.path.exists(inference_subdir):
                    data_sources[item] = {
                        'type': 'app_scenario',
                        'path': inference_subdir
                    }
                    print(f"‚úÖ Found app.py scenario data: {item}")
    
    return data_sources

def load_csv_data(file_path):
    """Safely load CSV data"""
    try:
        return pd.read_csv(file_path)
    except Exception as e:
        print(f"‚ö†Ô∏è  Could not load {file_path}: {e}")
        return None

def is_grid_regular(X, Y, tolerance=1e-6):
    """Check if grid is regular (equally spaced) for streamplot"""
    try:
        # Check if x spacing is regular
        x_row = X[0, :]
        x_diff = np.diff(x_row)
        x_regular = np.allclose(x_diff, x_diff[0], atol=tolerance)
        
        # Check if y spacing is regular
        y_col = Y[:, 0]
        y_diff = np.diff(y_col)
        y_regular = np.allclose(y_diff, y_diff[0], atol=tolerance)
        
        return x_regular and y_regular
    except:
        return False

def create_regular_grid(X, Y, u_grid, v_grid, nx_new=None, ny_new=None):
    """Create a regular grid from irregular data using interpolation"""
    try:
        from scipy.interpolate import griddata
        
        # Default grid size
        if nx_new is None:
            nx_new = min(50, X.shape[0])
        if ny_new is None:
            ny_new = min(25, X.shape[1])
        
        # Create regular grid
        x_min, x_max = X.min(), X.max()
        y_min, y_max = Y.min(), Y.max()
        
        x_reg = np.linspace(x_min, x_max, nx_new)
        y_reg = np.linspace(y_min, y_max, ny_new)
        X_reg, Y_reg = np.meshgrid(x_reg, y_reg, indexing='ij')
        
        # Flatten original data for interpolation
        points = np.column_stack((X.ravel(), Y.ravel()))
        
        # Interpolate u and v to regular grid
        u_reg = griddata(points, u_grid.ravel(), (X_reg, Y_reg), method='linear', fill_value=0)
        v_reg = griddata(points, v_grid.ravel(), (X_reg, Y_reg), method='linear', fill_value=0)
        
        return X_reg, Y_reg, u_reg, v_reg
    except ImportError:
        # If scipy not available, return None
        print("‚ö†Ô∏è  Scipy not available for grid interpolation, using quiver plot instead")
        return None, None, None, None
    except Exception as e:
        print(f"‚ö†Ô∏è  Grid regularization failed: {e}")
        return None, None, None, None
    """Safely load CSV data"""
    try:
        return pd.read_csv(file_path)
    except Exception as e:
        print(f"‚ö†Ô∏è  Could not load {file_path}: {e}")
        return None

def generate_single_flow_field_robust(source_name, source_info, save_dir):
    """Generate flow field visualization for a single scenario (robust version)"""
    flow_file = os.path.join(source_info['path'], 'inferred_flow_3d_complete.csv')
    
    if not os.path.exists(flow_file):
        print(f"‚ö†Ô∏è  No flow data found for {source_name}")
        return None
    
    flow_data = load_csv_data(flow_file)
    if flow_data is None:
        return None
    
    print(f"üìä Generating flow fields for: {source_name}")
    
    # Load metadata if available
    metadata = {}
    metadata_file = os.path.join(source_info['path'], 'inference_summary.json')
    if os.path.exists(metadata_file):
        try:
            with open(metadata_file, 'r') as f:
                metadata = json.load(f)
        except:
            pass
    
    # Determine grid structure
    if 'grid_i' in flow_data.columns and 'grid_j' in flow_data.columns:
        grid_i = flow_data['grid_i'].values
        grid_j = flow_data['grid_j'].values
        nx = grid_i.max() + 1
        ny = grid_j.max() + 1
        X = flow_data['x'].values.reshape(nx, ny)
        Y = flow_data['y'].values.reshape(nx, ny)
    else:
        x_unique = sorted(flow_data['x'].unique())
        y_unique = sorted(flow_data['y'].unique())
        nx, ny = len(x_unique), len(y_unique)
        X, Y = np.meshgrid(x_unique, y_unique, indexing='ij')
    
    # Reshape field data
    try:
        u_grid = flow_data['u_velocity'].values.reshape(nx, ny)
        v_grid = flow_data['v_velocity'].values.reshape(nx, ny)
        p_grid = flow_data['pressure'].values.reshape(nx, ny)
        
        if 'velocity_magnitude' in flow_data.columns:
            vel_mag = flow_data['velocity_magnitude'].values.reshape(nx, ny)
        else:
            vel_mag = np.sqrt(u_grid**2 + v_grid**2)
        
        if 'vorticity' in flow_data.columns:
            vorticity = flow_data['vorticity'].values.reshape(nx, ny)
        else:
            dx = (X.max() - X.min()) / (nx - 1)
            dy = (Y.max() - Y.min()) / (ny - 1)
            u_y = np.gradient(u_grid, dy, axis=1)
            v_x = np.gradient(v_grid, dx, axis=0)
            vorticity = v_x - u_y
            
    except Exception as e:
        print(f"‚ùå Error reshaping data for {source_name}: {e}")
        return None
    
    # Create detailed flow field visualization - NO STREAMPLOT
    fig, axs = plt.subplots(2, 3, figsize=(18, 12))
    
    # Extract scenario info
    learned_param = flow_data['learned_viscosity_param'].iloc[0] if 'learned_viscosity_param' in flow_data.columns else "N/A"
    reynolds = metadata.get('inference_info', {}).get('reynolds_number', "N/A")
    
    fig.suptitle(f'Flow Field Analysis: {source_name.replace("_", " ").title()}\n'
                 f'Re = {reynolds}, Learned Parameter = {learned_param}', 
                 fontsize=16, fontweight='bold')
    
    # 1. U velocity with velocity vectors (NO STREAMPLOT)
    im0 = axs[0, 0].contourf(X, Y, u_grid, 50, cmap='viridis')
    stride = max(1, nx//15)
    axs[0, 0].quiver(X[::stride, ::stride], Y[::stride, ::stride], 
                   u_grid[::stride, ::stride], v_grid[::stride, ::stride],
                   color='white', scale=20, width=0.002, alpha=0.8)
    plt.colorbar(im0, ax=axs[0, 0], label='U Velocity (m/s)')
    axs[0, 0].set_xlabel('X (m)')
    axs[0, 0].set_ylabel('Y (m)')
    axs[0, 0].set_title('U-Velocity with Vectors', fontweight='bold')
    
    # 2. V velocity
    im1 = axs[0, 1].contourf(X, Y, v_grid, 50, cmap='RdBu_r')
    plt.colorbar(im1, ax=axs[0, 1], label='V Velocity (m/s)')
    axs[0, 1].set_xlabel('X (m)')
    axs[0, 1].set_ylabel('Y (m)')
    axs[0, 1].set_title('V-Velocity Field', fontweight='bold')
    
    # 3. Pressure field
    im2 = axs[0, 2].contourf(X, Y, p_grid, 50, cmap='plasma')
    plt.colorbar(im2, ax=axs[0, 2], label='Pressure (Pa)')
    axs[0, 2].set_xlabel('X (m)')
    axs[0, 2].set_ylabel('Y (m)')
    axs[0, 2].set_title('Pressure Field', fontweight='bold')
    
    # 4. Velocity magnitude with vectors
    im3 = axs[1, 0].contourf(X, Y, vel_mag, 50, cmap='viridis')
    axs[1, 0].quiver(X[::stride, ::stride], Y[::stride, ::stride], 
                     u_grid[::stride, ::stride], v_grid[::stride, ::stride],
                     color='white', scale=25, width=0.003)
    plt.colorbar(im3, ax=axs[1, 0], label='Velocity Magnitude (m/s)')
    axs[1, 0].set_xlabel('X (m)')
    axs[1, 0].set_ylabel('Y (m)')
    axs[1, 0].set_title('Velocity Magnitude & Vectors', fontweight='bold')
    
    # 5. Vorticity field
    im4 = axs[1, 1].contourf(X, Y, vorticity, 50, cmap='RdBu_r')
    plt.colorbar(im4, ax=axs[1, 1], label='Vorticity (1/s)')
    axs[1, 1].set_xlabel('X (m)')
    axs[1, 1].set_ylabel('Y (m)')
    axs[1, 1].set_title('Vorticity Field', fontweight='bold')
    
    # 6. Centerline velocity profile
    y_center_idx = ny // 2
    u_centerline = u_grid[:, y_center_idx]
    x_centerline = X[:, y_center_idx]
    axs[1, 2].plot(x_centerline, u_centerline, 'b-', linewidth=2, label='Centerline U')
    axs[1, 2].set_xlabel('X (m)')
    axs[1, 2].set_ylabel('U Velocity (m/s)')
    axs[1, 2].set_title('Centerline Velocity Profile', fontweight='bold')
    axs[1, 2].grid(True, alpha=0.3)
    axs[1, 2].legend()
    
    plt.tight_layout()
    
    # Save individual scenario
    clean_name = source_name.replace('inference_', '').replace('scenario_', '')
    save_path = os.path.join(save_dir, f'flow_fields_{clean_name}.png')
    plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white')
    plt.close()
    
    return save_path
    """Generate flow field visualization for a single scenario"""
    flow_file = os.path.join(source_info['path'], 'inferred_flow_3d_complete.csv')
    
    if not os.path.exists(flow_file):
        print(f"‚ö†Ô∏è  No flow data found for {source_name}")
        return None
    
    flow_data = load_csv_data(flow_file)
    if flow_data is None:
        return None
    
    print(f"üìä Generating flow fields for: {source_name}")
    
    # Load metadata if available
    metadata = {}
    metadata_file = os.path.join(source_info['path'], 'inference_summary.json')
    if os.path.exists(metadata_file):
        try:
            with open(metadata_file, 'r') as f:
                metadata = json.load(f)
        except:
            pass
    
    # Determine grid structure
    if 'grid_i' in flow_data.columns and 'grid_j' in flow_data.columns:
        grid_i = flow_data['grid_i'].values
        grid_j = flow_data['grid_j'].values
        nx = grid_i.max() + 1
        ny = grid_j.max() + 1
        X = flow_data['x'].values.reshape(nx, ny)
        Y = flow_data['y'].values.reshape(nx, ny)
    else:
        x_unique = sorted(flow_data['x'].unique())
        y_unique = sorted(flow_data['y'].unique())
        nx, ny = len(x_unique), len(y_unique)
        X, Y = np.meshgrid(x_unique, y_unique, indexing='ij')
    
    # Reshape field data
    try:
        u_grid = flow_data['u_velocity'].values.reshape(nx, ny)
        v_grid = flow_data['v_velocity'].values.reshape(nx, ny)
        p_grid = flow_data['pressure'].values.reshape(nx, ny)
        
        if 'velocity_magnitude' in flow_data.columns:
            vel_mag = flow_data['velocity_magnitude'].values.reshape(nx, ny)
        else:
            vel_mag = np.sqrt(u_grid**2 + v_grid**2)
        
        if 'vorticity' in flow_data.columns:
            vorticity = flow_data['vorticity'].values.reshape(nx, ny)
        else:
            dx = (X.max() - X.min()) / (nx - 1)
            dy = (Y.max() - Y.min()) / (ny - 1)
            u_y = np.gradient(u_grid, dy, axis=1)
            v_x = np.gradient(v_grid, dx, axis=0)
            vorticity = v_x - u_y
            
    except Exception as e:
        print(f"‚ùå Error reshaping data for {source_name}: {e}")
        return None
    
    # Create detailed flow field visualization
    fig, axs = plt.subplots(2, 3, figsize=(18, 12))
    
    # Extract scenario info
    learned_param = flow_data['learned_viscosity_param'].iloc[0] if 'learned_viscosity_param' in flow_data.columns else "N/A"
    reynolds = metadata.get('inference_info', {}).get('reynolds_number', "N/A")
    
    fig.suptitle(f'Flow Field Analysis: {source_name.replace("_", " ").title()}\n'
                 f'Re = {reynolds}, Learned Parameter = {learned_param}', 
                 fontsize=16, fontweight='bold')
    
    # U velocity with streamlines
    im0 = axs[0, 0].contourf(X, Y, u_grid, 50, cmap='viridis')
    axs[0, 0].streamplot(X.T, Y.T, u_grid.T, v_grid.T, density=1.5, color='white', linewidth=0.8)
    plt.colorbar(im0, ax=axs[0, 0], label='U Velocity (m/s)')
    axs[0, 0].set_xlabel('X (m)')
    axs[0, 0].set_ylabel('Y (m)')
    axs[0, 0].set_title('U-Velocity with Streamlines', fontweight='bold')
    
    # V velocity
    im1 = axs[0, 1].contourf(X, Y, v_grid, 50, cmap='RdBu_r')
    plt.colorbar(im1, ax=axs[0, 1], label='V Velocity (m/s)')
    axs[0, 1].set_xlabel('X (m)')
    axs[0, 1].set_ylabel('Y (m)')
    axs[0, 1].set_title('V-Velocity Field', fontweight='bold')
    
    # Pressure field
    im2 = axs[0, 2].contourf(X, Y, p_grid, 50, cmap='plasma')
    plt.colorbar(im2, ax=axs[0, 2], label='Pressure (Pa)')
    axs[0, 2].set_xlabel('X (m)')
    axs[0, 2].set_ylabel('Y (m)')
    axs[0, 2].set_title('Pressure Field', fontweight='bold')
    
    # Velocity magnitude with vectors
    im3 = axs[1, 0].contourf(X, Y, vel_mag, 50, cmap='viridis')
    stride = max(1, nx//20)
    axs[1, 0].quiver(X[::stride, ::stride], Y[::stride, ::stride], 
                     u_grid[::stride, ::stride], v_grid[::stride, ::stride],
                     color='white', scale=25, width=0.003)
    plt.colorbar(im3, ax=axs[1, 0], label='Velocity Magnitude (m/s)')
    axs[1, 0].set_xlabel('X (m)')
    axs[1, 0].set_ylabel('Y (m)')
    axs[1, 0].set_title('Velocity Magnitude & Vectors', fontweight='bold')
    
    # Vorticity field
    im4 = axs[1, 1].contourf(X, Y, vorticity, 50, cmap='RdBu_r')
    plt.colorbar(im4, ax=axs[1, 1], label='Vorticity (1/s)')
    axs[1, 1].set_xlabel('X (m)')
    axs[1, 1].set_ylabel('Y (m)')
    axs[1, 1].set_title('Vorticity Field', fontweight='bold')
    
    # Centerline velocity profile
    y_center_idx = ny // 2
    u_centerline = u_grid[:, y_center_idx]
    x_centerline = X[:, y_center_idx]
    axs[1, 2].plot(x_centerline, u_centerline, 'b-', linewidth=2, label='Centerline U')
    axs[1, 2].set_xlabel('X (m)')
    axs[1, 2].set_ylabel('U Velocity (m/s)')
    axs[1, 2].set_title('Centerline Velocity Profile', fontweight='bold')
    axs[1, 2].grid(True, alpha=0.3)
    axs[1, 2].legend()
    
    plt.tight_layout()
    
    # Save individual scenario
    clean_name = source_name.replace('inference_', '').replace('scenario_', '')
    save_path = os.path.join(save_dir, f'flow_fields_{clean_name}.png')
    plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white')
    plt.close()
    
    return save_path

def generate_flow_field_visualizations(data_sources, save_dir):
    """Generate flow field visualizations for ALL scenarios"""
    print("\nüé® Generating flow field visualizations for each scenario...")
    
    generated_files = []
    
    # Generate individual flow fields for each scenario using robust method
    for source_name, source_info in data_sources.items():
        try:
            flow_path = generate_single_flow_field(source_name, source_info, save_dir)
            if flow_path:
                generated_files.append(flow_path)
                print(f"‚úÖ Generated: {flow_path}")
        except Exception as e:
            print(f"‚ùå Failed to generate flow field for {source_name}: {e}")
            continue
    
    if not generated_files:
        print("‚ùå No flow field visualizations could be generated")
        return []
    
    # Generate a combined comparison if we have multiple scenarios
    if len(generated_files) > 1:
        try:
            comparison_path = generate_flow_field_comparison(data_sources, save_dir)
            if comparison_path:
                generated_files.append(comparison_path)
        except Exception as e:
            print(f"‚ö†Ô∏è  Flow field comparison failed: {e}")
    
    print(f"‚úÖ Generated {len(generated_files)} flow field visualizations")
    return generated_files

def generate_flow_field_comparison(data_sources, save_dir):
    """Generate a comparison plot showing multiple scenarios side by side"""
    print("üìä Creating flow field comparison...")
    
    # Collect data from all sources
    scenario_data = []
    for source_name, source_info in data_sources.items():
        flow_file = os.path.join(source_info['path'], 'inferred_flow_3d_complete.csv')
        if os.path.exists(flow_file):
            flow_data = load_csv_data(flow_file)
            if flow_data is not None:
                scenario_data.append({
                    'name': source_name.replace('_', ' ').title(),
                    'data': flow_data,
                    'source_info': source_info
                })
    
    if len(scenario_data) < 2:
        return None
    
    # Create comparison figure
    n_scenarios = len(scenario_data)
    fig, axs = plt.subplots(n_scenarios, 3, figsize=(15, 5*n_scenarios))
    if n_scenarios == 1:
        axs = axs.reshape(1, -1)
    
    fig.suptitle('Flow Field Comparison Across Scenarios', fontsize=16, fontweight='bold')
    
    for i, scenario in enumerate(scenario_data):
        flow_data = scenario['data']
        
        # Process grid data
        if 'grid_i' in flow_data.columns and 'grid_j' in flow_data.columns:
            grid_i = flow_data['grid_i'].values
            grid_j = flow_data['grid_j'].values
            nx = grid_i.max() + 1
            ny = grid_j.max() + 1
            X = flow_data['x'].values.reshape(nx, ny)
            Y = flow_data['y'].values.reshape(nx, ny)
        else:
            x_unique = sorted(flow_data['x'].unique())
            y_unique = sorted(flow_data['y'].unique())
            nx, ny = len(x_unique), len(y_unique)
            X, Y = np.meshgrid(x_unique, y_unique, indexing='ij')
        
        u_grid = flow_data['u_velocity'].values.reshape(nx, ny)
        v_grid = flow_data['v_velocity'].values.reshape(nx, ny)
        p_grid = flow_data['pressure'].values.reshape(nx, ny)
        vel_mag = np.sqrt(u_grid**2 + v_grid**2)
        
        learned_param = flow_data['learned_viscosity_param'].iloc[0] if 'learned_viscosity_param' in flow_data.columns else "N/A"
        
        # Plot velocity magnitude
        im1 = axs[i, 0].contourf(X, Y, vel_mag, 50, cmap='viridis')
        plt.colorbar(im1, ax=axs[i, 0])
        axs[i, 0].set_title(f'{scenario["name"]}\nVelocity Magnitude')
        axs[i, 0].set_ylabel('Y (m)')
        
        # Plot pressure
        im2 = axs[i, 1].contourf(X, Y, p_grid, 50, cmap='plasma')
        plt.colorbar(im2, ax=axs[i, 1])
        axs[i, 1].set_title(f'Pressure\nParam: {learned_param}')
        
        # Plot flow vectors (avoiding streamplot issues)
        try:
            stride = max(1, nx//10)
            axs[i, 2].quiver(X[::stride, ::stride], Y[::stride, ::stride], 
                           u_grid[::stride, ::stride], v_grid[::stride, ::stride],
                           color='blue', scale=15, alpha=0.8, width=0.003)
            axs[i, 2].contourf(X, Y, vel_mag, 20, cmap='viridis', alpha=0.6)
            axs[i, 2].set_title('Flow Vectors')
        except Exception as e:
            print(f"‚ö†Ô∏è  Vector plot failed for {scenario['name']}: {e}")
            # Just show velocity magnitude
            axs[i, 2].contourf(X, Y, vel_mag, 20, cmap='viridis')
            axs[i, 2].set_title('Velocity Magnitude')
        
        # Set x-labels only for bottom row
        if i == n_scenarios - 1:
            axs[i, 0].set_xlabel('X (m)')
            axs[i, 1].set_xlabel('X (m)')
            axs[i, 2].set_xlabel('X (m)')
    
    plt.tight_layout()
    
    save_path = os.path.join(save_dir, 'flow_fields_comparison.png')
    plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white')
    plt.close()
    
    print(f"‚úÖ Flow field comparison saved: {save_path}")
    return save_path

def generate_single_viscosity_analysis(source_name, source_info, save_dir):
    """Generate viscosity analysis for a single scenario"""
    visc_file = os.path.join(source_info['path'], 'inferred_viscosity_profile.csv')
    
    if not os.path.exists(visc_file):
        print(f"‚ö†Ô∏è  No viscosity data found for {source_name}")
        return None
    
    viscosity_data = load_csv_data(visc_file)
    if viscosity_data is None:
        return None
    
    print(f"üî¨ Generating viscosity analysis for: {source_name}")
    
    # Load metadata if available
    metadata = {}
    metadata_file = os.path.join(source_info['path'], 'inference_summary.json')
    if os.path.exists(metadata_file):
        try:
            with open(metadata_file, 'r') as f:
                metadata = json.load(f)
        except:
            pass
    
    # Create viscosity analysis
    fig, axs = plt.subplots(2, 2, figsize=(15, 10))
    
    # Extract data
    y_profile = viscosity_data['y'].values
    nu_learned = viscosity_data['viscosity_learned'].values
    nu_reference = viscosity_data['viscosity_reference'].values
    learned_param = viscosity_data['learned_viscosity_param'].iloc[0]
    reference_param = viscosity_data['reference_viscosity_param'].iloc[0]
    base_viscosity = viscosity_data['base_viscosity'].iloc[0]
    
    reynolds = metadata.get('inference_info', {}).get('reynolds_number', "N/A")
    
    fig.suptitle(f'Viscosity Analysis: {source_name.replace("_", " ").title()}\n'
                 f'Re = {reynolds}', fontsize=16, fontweight='bold')
    
    # 1D viscosity profile comparison
    axs[0, 0].plot(y_profile, nu_learned, 'b-', linewidth=3, 
                   label=f'Learned: ŒΩ = {base_viscosity:.3f} + {learned_param:.4f}y')
    axs[0, 0].plot(y_profile, nu_reference, 'r--', linewidth=3, 
                   label=f'Reference: ŒΩ = {base_viscosity:.3f} + {reference_param:.4f}y')
    axs[0, 0].set_xlabel('Y (m)')
    axs[0, 0].set_ylabel('Viscosity (m¬≤/s)')
    axs[0, 0].set_title('Viscosity Profile Comparison', fontweight='bold')
    axs[0, 0].legend()
    axs[0, 0].grid(True, alpha=0.3)
    
    # Parameter comparison
    axs[0, 1].bar(['Reference', 'Learned'], [reference_param, learned_param], 
                  color=['red', 'blue'], alpha=0.7, edgecolor='black', linewidth=2)
    axs[0, 1].set_ylabel('Parameter Value')
    axs[0, 1].set_title('Parameter Comparison', fontweight='bold')
    axs[0, 1].grid(True, alpha=0.3, axis='y')
    
    # Add value annotations
    for i, val in enumerate([reference_param, learned_param]):
        axs[0, 1].annotate(f'{val:.4f}', xy=(i, val), xytext=(0, 3), 
                          textcoords="offset points", ha='center', va='bottom',
                          fontweight='bold')
    
    # Error analysis
    if 'relative_error_percent' in viscosity_data.columns:
        rel_error = viscosity_data['relative_error_percent'].values
        axs[1, 0].plot(y_profile, rel_error, 'orange', linewidth=2)
        axs[1, 0].set_xlabel('Y (m)')
        axs[1, 0].set_ylabel('Relative Error (%)')
        axs[1, 0].set_title('Relative Error Profile', fontweight='bold')
        axs[1, 0].grid(True, alpha=0.3)
        
        # Error histogram
        axs[1, 1].hist(rel_error, bins=20, alpha=0.7, color='orange', edgecolor='black')
        axs[1, 1].set_xlabel('Relative Error (%)')
        axs[1, 1].set_ylabel('Frequency')
        axs[1, 1].set_title('Error Distribution', fontweight='bold')
        axs[1, 1].grid(True, alpha=0.3)
    
    plt.tight_layout()
    
    # Save individual scenario
    clean_name = source_name.replace('inference_', '').replace('scenario_', '')
    save_path = os.path.join(save_dir, f'viscosity_analysis_{clean_name}.png')
    plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white')
    plt.close()
    
    return save_path

def generate_viscosity_analyses(data_sources, save_dir):
    """Generate viscosity analyses for ALL scenarios"""
    print("\nüî¨ Generating viscosity analyses for each scenario...")
    
    generated_files = []
    
    # Generate individual viscosity analyses for each scenario
    for source_name, source_info in data_sources.items():
        visc_path = generate_single_viscosity_analysis(source_name, source_info, save_dir)
        if visc_path:
            generated_files.append(visc_path)
            print(f"‚úÖ Generated: {visc_path}")
    
    if not generated_files:
        print("‚ùå No viscosity analyses could be generated")
        return []
    
    print(f"‚úÖ Generated {len(generated_files)} viscosity analyses")
    return generated_files
    """Generate viscosity analysis from existing data"""
    print("\nüî¨ Generating viscosity analysis...")
    
    # Look for viscosity profile data
    viscosity_data = None
    data_source_name = "unknown"
    
    for source_name, source_info in data_sources.items():
        visc_file = os.path.join(source_info['path'], 'inferred_viscosity_profile.csv')
        if os.path.exists(visc_file):
            viscosity_data = load_csv_data(visc_file)
            if viscosity_data is not None:
                data_source_name = source_name
                print(f"üìä Using viscosity data from: {source_name}")
                break
    
    if viscosity_data is None:
        print("‚ùå No viscosity profile data found")
        return None
    
    # Create viscosity analysis
    fig, axs = plt.subplots(2, 3, figsize=(18, 12))
    fig.suptitle(f'PINN Viscosity Inference Analysis\nData Source: {data_source_name}', 
                 fontsize=16, fontweight='bold')
    
    # Extract data
    y_profile = viscosity_data['y'].values
    nu_learned = viscosity_data['viscosity_learned'].values
    nu_reference = viscosity_data['viscosity_reference'].values
    learned_param = viscosity_data['learned_viscosity_param'].iloc[0]
    reference_param = viscosity_data['reference_viscosity_param'].iloc[0]
    base_viscosity = viscosity_data['base_viscosity'].iloc[0]
    
    # 1D viscosity profile comparison
    axs[0, 0].plot(y_profile, nu_learned, 'b-', linewidth=3, 
                   label=f'Learned: ŒΩ = {base_viscosity:.3f} + {learned_param:.4f}y')
    axs[0, 0].plot(y_profile, nu_reference, 'r--', linewidth=3, 
                   label=f'Reference: ŒΩ = {base_viscosity:.3f} + {reference_param:.4f}y')
    axs[0, 0].set_xlabel('Y (m)')
    axs[0, 0].set_ylabel('Viscosity (m¬≤/s)')
    axs[0, 0].set_title('Viscosity Profile Comparison', fontweight='bold')
    axs[0, 0].legend()
    axs[0, 0].grid(True, alpha=0.3)
    
    # Error analysis
    if 'absolute_error' in viscosity_data.columns:
        abs_error = viscosity_data['absolute_error'].values
        rel_error = viscosity_data['relative_error_percent'].values
        
        axs[0, 1].plot(y_profile, abs_error, 'purple', linewidth=2, label='Absolute Error')
        ax_twin = axs[0, 1].twinx()
        ax_twin.plot(y_profile, rel_error, 'orange', linewidth=2, label='Relative Error (%)')
        ax_twin.set_ylabel('Relative Error (%)', color='orange')
        
        axs[0, 1].set_xlabel('Y (m)')
        axs[0, 1].set_ylabel('Absolute Error (m¬≤/s)', color='purple')
        axs[0, 1].set_title('Error Analysis', fontweight='bold')
        axs[0, 1].grid(True, alpha=0.3)
    
    # Parameter comparison
    axs[0, 2].bar(['Reference', 'Learned'], [reference_param, learned_param], 
                  color=['red', 'blue'], alpha=0.7, edgecolor='black', linewidth=2)
    axs[0, 2].set_ylabel('Parameter Value')
    axs[0, 2].set_title('Parameter Comparison', fontweight='bold')
    axs[0, 2].grid(True, alpha=0.3, axis='y')
    
    # Add value annotations
    for i, val in enumerate([reference_param, learned_param]):
        axs[0, 2].annotate(f'{val:.4f}', xy=(i, val), xytext=(0, 3), 
                          textcoords="offset points", ha='center', va='bottom',
                          fontweight='bold')
    
    # Statistics summary
    axs[1, 0].axis('off')
    abs_param_error = abs(learned_param - reference_param)
    rel_param_error = abs_param_error / reference_param * 100
    
    stats_text = f"""
Viscosity Parameter Analysis:

Reference Parameter: {reference_param:.6f}
Learned Parameter:   {learned_param:.6f}

Parameter Error:
‚Ä¢ Absolute:    {abs_param_error:.6f}
‚Ä¢ Relative:    {rel_param_error:.2f}%

Base Viscosity: {base_viscosity:.6f}
Data Source: {data_source_name}
"""
    
    axs[1, 0].text(0.1, 0.9, stats_text, transform=axs[1, 0].transAxes,
                   verticalalignment='top', fontfamily='monospace',
                   bbox=dict(boxstyle='round,pad=0.5', facecolor='lightblue', alpha=0.8))
    
    # Residual analysis
    if 'relative_error_percent' in viscosity_data.columns:
        residuals = nu_learned - nu_reference
        axs[1, 1].plot(y_profile, residuals, 'green', linewidth=2)
        axs[1, 1].axhline(y=0, color='black', linestyle='--', alpha=0.5)
        axs[1, 1].set_xlabel('Y (m)')
        axs[1, 1].set_ylabel('Residual (m¬≤/s)')
        axs[1, 1].set_title('Viscosity Residuals', fontweight='bold')
        axs[1, 1].grid(True, alpha=0.3)
        
        # Error histogram
        rel_error = viscosity_data['relative_error_percent'].values
        axs[1, 2].hist(rel_error, bins=20, alpha=0.7, color='orange', edgecolor='black')
        axs[1, 2].set_xlabel('Relative Error (%)')
        axs[1, 2].set_ylabel('Frequency')
        axs[1, 2].set_title('Error Distribution', fontweight='bold')
        axs[1, 2].grid(True, alpha=0.3)
    
    plt.tight_layout()
    
    # Save
    save_path = os.path.join(save_dir, 'viscosity_inference_analysis.png')
    plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white')
    plt.close()
    
    print(f"‚úÖ Viscosity analysis saved: {save_path}")
    return save_path

def generate_3d_visualization(model, save_dir):
    """Generate 3D visualizations using existing model"""
    if model is None or not CONFIG_AVAILABLE:
        print("‚ö†Ô∏è  Cannot generate 3D visualizations: model not available")
        return None
        
    print("\nüé® Generating 3D visualizations...")
    
    # Create grid for 3D visualization
    nx, ny = 80, 40
    x = torch.linspace(cfg.X_MIN, cfg.X_MAX, nx, device=cfg.DEVICE)
    y = torch.linspace(cfg.Y_MIN, cfg.Y_MAX, ny, device=cfg.DEVICE)
    X, Y = torch.meshgrid(x, y, indexing='ij')
    x_flat = X.reshape(-1, 1)
    y_flat = Y.reshape(-1, 1)
    
    # Predict flow field using existing model
    with torch.no_grad():
        u_pred, v_pred, p_pred = model.uvp(x_flat, y_flat)
    
    # Convert to numpy and reshape
    u_grid = u_pred.reshape(nx, ny).cpu().numpy()
    v_grid = v_pred.reshape(nx, ny).cpu().numpy()
    p_grid = p_pred.reshape(nx, ny).cpu().numpy()
    X_np = X.cpu().numpy()
    Y_np = Y.cpu().numpy()
    
    # Calculate derived quantities
    vel_mag = np.sqrt(u_grid**2 + v_grid**2)
    
    # Create 3D visualization
    fig = plt.figure(figsize=(20, 15))
    
    # 3D velocity magnitude surface
    ax1 = fig.add_subplot(2, 3, 1, projection='3d')
    surf1 = ax1.plot_surface(X_np, Y_np, vel_mag, cmap='viridis', alpha=0.9,
                            linewidth=0, antialiased=True)
    ax1.set_xlabel('X (m)')
    ax1.set_ylabel('Y (m)')
    ax1.set_zlabel('Velocity Magnitude (m/s)')
    ax1.set_title('3D Velocity Magnitude', fontweight='bold')
    fig.colorbar(surf1, ax=ax1, shrink=0.5, aspect=10)
    
    # 3D pressure surface
    ax2 = fig.add_subplot(2, 3, 2, projection='3d')
    surf2 = ax2.plot_surface(X_np, Y_np, p_grid, cmap='plasma', alpha=0.9,
                            linewidth=0, antialiased=True)
    ax2.set_xlabel('X (m)')
    ax2.set_ylabel('Y (m)')
    ax2.set_zlabel('Pressure (Pa)')
    ax2.set_title('3D Pressure Field', fontweight='bold')
    fig.colorbar(surf2, ax=ax2, shrink=0.5, aspect=10)
    
    # 3D U velocity surface
    ax3 = fig.add_subplot(2, 3, 3, projection='3d')
    surf3 = ax3.plot_surface(X_np, Y_np, u_grid, cmap='viridis', alpha=0.9,
                            linewidth=0, antialiased=True)
    ax3.set_xlabel('X (m)')
    ax3.set_ylabel('Y (m)')
    ax3.set_zlabel('U Velocity (m/s)')
    ax3.set_title('3D U-Velocity Field', fontweight='bold')
    fig.colorbar(surf3, ax=ax3, shrink=0.5, aspect=10)
    
    # 3D surface with contours
    ax4 = fig.add_subplot(2, 3, 4, projection='3d')
    surf4 = ax4.plot_surface(X_np, Y_np, vel_mag, cmap='viridis', alpha=0.7)
    ax4.contour(X_np, Y_np, vel_mag, levels=10, colors='red', alpha=0.8)
    ax4.set_xlabel('X (m)')
    ax4.set_ylabel('Y (m)')
    ax4.set_zlabel('Velocity Magnitude (m/s)')
    ax4.set_title('3D Surface with Contours', fontweight='bold')
    
    # 3D vector field (subsampled)
    ax5 = fig.add_subplot(2, 3, 5, projection='3d')
    stride = 6
    X_sub = X_np[::stride, ::stride]
    Y_sub = Y_np[::stride, ::stride]
    U_sub = u_grid[::stride, ::stride]
    V_sub = v_grid[::stride, ::stride]
    
    ax5.quiver(X_sub, Y_sub, np.zeros_like(X_sub), U_sub, V_sub, np.zeros_like(U_sub),
              length=0.1, normalize=True, color='red', alpha=0.8)
    ax5.set_xlabel('X (m)')
    ax5.set_ylabel('Y (m)')
    ax5.set_zlabel('Z')
    ax5.set_title('3D Velocity Vectors', fontweight='bold')
    
    # Combined visualization
    ax6 = fig.add_subplot(2, 3, 6, projection='3d')
    surf6 = ax6.plot_surface(X_np, Y_np, vel_mag, cmap='viridis', alpha=0.6)
    ax6.quiver(X_sub, Y_sub, vel_mag[::stride, ::stride], U_sub, V_sub, np.zeros_like(U_sub),
              length=0.05, normalize=True, color='white', alpha=0.9)
    ax6.set_xlabel('X (m)')
    ax6.set_ylabel('Y (m)')
    ax6.set_zlabel('Velocity Magnitude (m/s)')
    ax6.set_title('Combined 3D Flow Visualization', fontweight='bold')
    
    # Add model info
    learned_param = model.get_inferred_viscosity_param()
    plt.suptitle(f'PINN 3D Flow Field Visualization\nLearned Parameter: {learned_param:.4f}', 
                 fontsize=16, fontweight='bold', y=0.98)
    plt.tight_layout()
    
    # Save
    save_path = os.path.join(save_dir, 'publication_3d_visualization.png')
    plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white')
    plt.close()
    
    print(f"‚úÖ 3D visualization saved: {save_path}")
    return save_path

def generate_multi_scenario_comparison(data_sources, save_dir):
    """Generate multi-scenario comparison from app.py data"""
    print("\nüìä Generating multi-scenario comparison...")
    
    # Filter to app scenario data
    scenario_data = {k: v for k, v in data_sources.items() if v['type'] == 'app_scenario'}
    
    if not scenario_data:
        print("‚ö†Ô∏è  No app.py scenario data found for comparison")
        return None
    
    # Extract scenario information
    scenarios = []
    for scenario_id, scenario_info in scenario_data.items():
        # Try to load metadata
        metadata_file = os.path.join(scenario_info['path'], 'inference_summary.json')
        if os.path.exists(metadata_file):
            try:
                with open(metadata_file, 'r') as f:
                    metadata = json.load(f)
                
                scenarios.append({
                    'id': scenario_id,
                    'name': scenario_id.replace('_', ' ').title(),
                    'learned_param': metadata['inference_info']['learned_viscosity_param'],
                    'reynolds': metadata['inference_info']['reynolds_number'],
                    'total_points': metadata['inference_info']['total_inference_points']
                })
            except Exception as e:
                print(f"‚ö†Ô∏è  Could not load metadata for {scenario_id}: {e}")
    
    if not scenarios:
        print("‚ùå No valid scenario metadata found")
        return None
    
    # Create comparison plots
    fig, axs = plt.subplots(2, 2, figsize=(15, 12))
    fig.suptitle('Multi-Scenario Analysis from App Data', fontsize=16, fontweight='bold')
    
    # Parameter comparison
    scenario_names = [s['name'] for s in scenarios]
    learned_params = [s['learned_param'] for s in scenarios]
    
    axs[0, 0].bar(scenario_names, learned_params, color='blue', alpha=0.7, edgecolor='black')
    axs[0, 0].set_ylabel('Learned Parameter Value')
    axs[0, 0].set_title('Parameter Inference Results', fontweight='bold')
    axs[0, 0].grid(True, alpha=0.3, axis='y')
    plt.setp(axs[0, 0].xaxis.get_majorticklabels(), rotation=45)
    
    # Reynolds number vs parameter
    reynolds_numbers = [s['reynolds'] for s in scenarios]
    axs[0, 1].scatter(reynolds_numbers, learned_params, s=100, alpha=0.7, c='red', edgecolors='black')
    for i, scenario in enumerate(scenarios):
        axs[0, 1].annotate(scenario['name'], 
                          (scenario['reynolds'], scenario['learned_param']),
                          xytext=(5, 5), textcoords='offset points', fontsize=9)
    
    axs[0, 1].set_xlabel('Reynolds Number')
    axs[0, 1].set_ylabel('Learned Parameter')
    axs[0, 1].set_title('Parameter vs Reynolds Number', fontweight='bold')
    axs[0, 1].grid(True, alpha=0.3)
    
    # Grid resolution comparison
    total_points = [s['total_points'] for s in scenarios]
    axs[1, 0].bar(scenario_names, total_points, color='green', alpha=0.7)
    axs[1, 0].set_ylabel('Total Inference Points')
    axs[1, 0].set_title('Grid Resolution', fontweight='bold')
    axs[1, 0].grid(True, alpha=0.3, axis='y')
    plt.setp(axs[1, 0].xaxis.get_majorticklabels(), rotation=45)
    
    # Summary statistics
    axs[1, 1].axis('off')
    
    summary_text = f"""
Multi-Scenario Analysis Summary:

Scenarios Processed: {len(scenarios)}
Reynolds Range: {min(reynolds_numbers)} - {max(reynolds_numbers)}
Parameter Range: {min(learned_params):.4f} - {max(learned_params):.4f}

Average Parameter: {np.mean(learned_params):.4f}
Parameter Std Dev:  {np.std(learned_params):.4f}

Total Points: {sum(total_points):,}

Data Source: FastAPI App Scenarios
Generated from existing inference data
"""
    
    axs[1, 1].text(0.05, 0.95, summary_text, transform=axs[1, 1].transAxes,
                   verticalalignment='top', fontfamily='monospace',
                   bbox=dict(boxstyle='round,pad=0.5', facecolor='lightcyan', alpha=0.8))
    
    plt.tight_layout()
    
    # Save
    save_path = os.path.join(save_dir, 'multi_scenario_comparison.png')
    plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white')
    plt.close()
    
    print(f"‚úÖ Multi-scenario comparison saved: {save_path}")
    return save_path

def create_summary_report(output_dir, generated_files):
    """Create a comprehensive summary report"""
    print("\nüìù Creating summary report...")
    
    report_content = f"""
# PINN Visualization Report

Generated on: {time.strftime('%Y-%m-%d %H:%M:%S')}

## Overview
This report contains visualization files generated from existing PINN data,
using results from interactive.py, app.py, and trained models from main.py.

## Generated Files
"""

    for category, files in generated_files.items():
        if files:
            report_content += f"\n### {category}\n"
            if isinstance(files, list):
                for file_path in files:
                    # Get just the filename for cleaner display
                    filename = os.path.basename(file_path)
                    report_content += f"- {filename}\n"
            else:
                filename = os.path.basename(files)
                report_content += f"- {filename}\n"

    report_content += f"""

## Usage for Presentation
These visualization files can be used directly in slides:
- **Flow Fields**: Replace generic flow visualizations
- **Viscosity Analysis**: Show parameter inference accuracy
- **3D Visualizations**: Demonstrate advanced capabilities
- **Multi-Scenario**: Compare different flow conditions

## Data Sources
The visualizations were generated from:
- Trained PINN models (from main.py)
- Inference data (from interactive.py)
- Scenario data (from app.py)

## Next Steps
1. Use high-resolution versions for presentations
2. Customize colors/labels as needed
3. Generate additional scenarios if required

Generated by: Fixed PINN Visualization Script
"""

    # Save report
    report_path = os.path.join(output_dir, 'visualization_report.md')
    with open(report_path, 'w') as f:
        f.write(report_content)
    
    print(f"‚úÖ Summary report saved: {report_path}")
    return report_path

def main():
    """Main function - simplified and working version"""
    parser = argparse.ArgumentParser(description="Generate PINN Presentation Visualizations")
    parser.add_argument("--force-regenerate", action="store_true", 
                       help="Force regeneration of all visualizations")
    
    args = parser.parse_args()
    
    print("="*70)
    print("üé® PINN Presentation Visualization Generator (FIXED)")
    print("Using Existing Data - No Retraining Required")
    print("="*70)
    
    # Setup output directory
    output_dir = setup_output_directory()
    print(f"üìÅ Output directory: {output_dir}")
    
    # Find all available data sources
    print("\nüîç Searching for existing data...")
    data_sources = find_data_directories()
    
    if not data_sources:
        print("‚ùå No data found!")
        print("Please run one of the following first:")
        print("  ‚Ä¢ python interactive.py")
        print("  ‚Ä¢ python app.py (and generate scenarios)")
        print("  ‚Ä¢ python main.py")
        return
    
    print(f"‚úÖ Found {len(data_sources)} data sources")
    
    # Load existing model
    model_path = "backend/results/trained_model.pth"
    model = load_existing_model(model_path)
    
    # Generate visualizations
    generated_files = {}
    
    # 1. Flow field visualizations (individual + comparison)
    flow_dir = os.path.join(output_dir, "flow_fields")
    flow_paths = generate_flow_field_visualizations(data_sources, flow_dir)
    if flow_paths:
        generated_files["Flow Fields"] = flow_paths
    
    # 2. Viscosity analysis (individual for each scenario)
    viscosity_dir = os.path.join(output_dir, "viscosity_analysis")
    viscosity_paths = generate_viscosity_analyses(data_sources, viscosity_dir)
    if viscosity_paths:
        generated_files["Viscosity Analysis"] = viscosity_paths
    
    # 3. 3D visualizations (if model is available)
    if model is not None:
        viz_3d_dir = os.path.join(output_dir, "3d_visualizations")
        try:
            viz_3d_path = generate_3d_visualization(model, viz_3d_dir)
            if viz_3d_path:
                generated_files["3D Visualizations"] = [viz_3d_path]
        except Exception as e:
            print(f"‚ö†Ô∏è  3D visualization failed: {e}")
            print("   Continuing with other visualizations...")
    else:
        print("‚ö†Ô∏è  Skipping 3D visualizations (no model available)")
        print("   To get 3D visualizations, ensure model can be loaded successfully")
    
    # 4. Multi-scenario comparison
    multi_dir = os.path.join(output_dir, "multi_scenario")
    multi_path = generate_multi_scenario_comparison(data_sources, multi_dir)
    if multi_path:
        generated_files["Multi-Scenario"] = [multi_path]
    
    # 5. Create summary report
    report_path = create_summary_report(output_dir, generated_files)
    generated_files["Documentation"] = [report_path]
    
    # Final summary
    print("\n" + "="*70)
    print("‚úÖ VISUALIZATION GENERATION COMPLETE")
    print("="*70)
    
    total_files = sum(len(files) if isinstance(files, list) else 1 for files in generated_files.values())
    print(f"üìä Generated {total_files} visualization files from {len(data_sources)} data sources")
    
    print("\nIndividual visualizations generated for each scenario:")
    flow_files = generated_files.get("Flow Fields", [])
    visc_files = generated_files.get("Viscosity Analysis", [])
    
    for flow_file in flow_files:
        if "comparison" not in flow_file:
            scenario_name = os.path.basename(flow_file).replace("flow_fields_", "").replace(".png", "")
            print(f"  üåä Flow fields: {scenario_name}")
    
    for visc_file in visc_files:
        scenario_name = os.path.basename(visc_file).replace("viscosity_analysis_", "").replace(".png", "")
        print(f"  üî¨ Viscosity analysis: {scenario_name}")
    
    if any("comparison" in f for f in flow_files):
        print(f"  üìä Plus flow field comparison visualization")
    
    print(f"\nüìÅ All files saved to: {output_dir}")
    print("\nGenerated visualizations:")
    for category, files in generated_files.items():
        print(f"\n{category}:")
        if isinstance(files, list):
            for file_path in files:
                print(f"  ‚úÖ {file_path}")
        else:
            print(f"  ‚úÖ {files}")
    
    print(f"\nüìã Detailed report: {report_path}")
    print("\nüéØ Ready for presentation use!")

if __name__ == "__main__":
    main()