"""
Extended FEniCSx solver for fluid dynamics problems with variable viscosity profiles.

This module extends the existing FEniCSx solver to handle diverse task configurations
generated by the FluidTaskGenerator, supporting various viscosity profiles and
boundary conditions for meta-learning applications.
"""

import logging
from dataclasses import dataclass
from typing import TYPE_CHECKING, Any, Dict, List, Optional, Tuple, Union

import numpy as np
import torch

from ..config.data_config import TaskConfig
from .analytical_solutions import AnalyticalSolution

logger = logging.getLogger(__name__)

# Check if FEniCSx is available
try:
    import dolfinx
    import dolfinx.fem as fem
    import dolfinx.io as io
    import dolfinx.mesh as mesh
    import ufl
    from mpi4py import MPI
    from petsc4py import PETSc

    FENICSX_AVAILABLE = True
except ImportError:
    FENICSX_AVAILABLE = False
    logger.warning(
        "FEniCSx not available. High-fidelity solver will not be functional."
    )
    # Create dummy types for type annotations when FEniCSx is not available
    if TYPE_CHECKING:
        import dolfinx


@dataclass
class SolverConfig:
    """Configuration for FEniCSx solver."""

    mesh_resolution: Tuple[int, int] = (100, 50)
    element_degree: int = 2
    pressure_degree: int = 1
    solver_type: str = "direct"  # 'direct', 'iterative'
    tolerance: float = 1e-8
    max_iterations: int = 1000
    use_stabilization: bool = False


class FEniCSxSolver:
    """
    Extended FEniCSx solver for variable viscosity fluid dynamics problems.

    Supports various viscosity profiles, geometries, and boundary conditions
    for generating high-fidelity ground truth data for meta-learning.
    """

    def __init__(self, solver_config: Optional[SolverConfig] = None):
        """
        Initialize the FEniCSx solver.

        Args:
            solver_config: Configuration for solver parameters
        """
        if not FENICSX_AVAILABLE:
            raise ImportError(
                "FEniCSx is required but not available. Please install FEniCSx."
            )

        self.solver_config = solver_config or SolverConfig()
        logger.info("Initialized FEniCSx solver")

    def solve_task(
        self, task_config: TaskConfig, coordinates: torch.Tensor
    ) -> AnalyticalSolution:
        """
        Solve fluid dynamics problem for given task configuration.

        Args:
            task_config: Task configuration specifying the problem
            coordinates: Coordinate points where to evaluate solution

        Returns:
            AnalyticalSolution object containing velocity, pressure, and metadata
        """
        logger.debug(
            f"Solving task {task_config.task_id} with {len(coordinates)} evaluation points"
        )

        try:
            # Validate task configuration
            self._validate_task_config(task_config)

            # Create mesh based on geometry
            domain = self._create_mesh(task_config)

            # Set up function spaces
            W, u, p, v, q = self._setup_function_spaces(domain)

            # Apply boundary conditions
            bcs = self._setup_boundary_conditions(task_config, W, domain)

            # Define viscosity function
            viscosity_expr = self._create_viscosity_function(task_config, domain)

            # Set up variational problem
            F = self._setup_variational_problem(
                task_config, u, p, v, q, viscosity_expr, domain
            )

            # Solve the problem
            w = self._solve_problem(F, bcs, W)

            # Extract solution and evaluate at query points
            solution = self._evaluate_solution(w, coordinates, task_config)

            # Validate solution quality
            self._validate_solution_quality(solution, task_config)

            return solution

        except Exception as e:
            logger.error(f"Failed to solve task {task_config.task_id}: {e}")
            # Return fallback solution with zeros
            return self._create_fallback_solution(coordinates, task_config, str(e))

    def _create_mesh(self, task_config: TaskConfig) -> Any:
        """Create computational mesh based on geometry configuration."""
        geometry_type = task_config.geometry_type
        geometry_params = task_config.geometry_params

        if geometry_type == "channel":
            # Rectangular channel
            length = geometry_params.get("length", 1.0)
            width = geometry_params.get("width", 1.0)

            nx, ny = self.solver_config.mesh_resolution
            domain = mesh.create_rectangle(
                MPI.COMM_WORLD,
                [[0.0, 0.0], [length, width]],
                [nx, ny],
                mesh.CellType.triangle,
            )

        elif geometry_type == "cavity":
            # Square cavity
            length = geometry_params.get("length", 1.0)
            width = geometry_params.get("width", 1.0)

            nx, ny = self.solver_config.mesh_resolution
            domain = mesh.create_rectangle(
                MPI.COMM_WORLD,
                [[0.0, 0.0], [length, width]],
                [nx, ny],
                mesh.CellType.triangle,
            )

        elif geometry_type == "cylinder":
            # Domain with cylinder (simplified as rectangle for now)
            # In a full implementation, this would use gmsh for complex geometries
            domain_length = geometry_params.get("domain_length", 2.0)
            domain_width = geometry_params.get("domain_width", 1.0)

            nx, ny = self.solver_config.mesh_resolution
            domain = mesh.create_rectangle(
                MPI.COMM_WORLD,
                [[0.0, 0.0], [domain_length, domain_width]],
                [nx, ny],
                mesh.CellType.triangle,
            )

        else:
            raise ValueError(f"Unsupported geometry type: {geometry_type}")

        return domain

    def _setup_function_spaces(self, domain):
        """Set up function spaces for velocity and pressure."""
        # Taylor-Hood elements (P2-P1)
        P2 = ufl.VectorElement(
            "Lagrange", domain.ufl_cell(), self.solver_config.element_degree
        )
        P1 = ufl.FiniteElement(
            "Lagrange", domain.ufl_cell(), self.solver_config.pressure_degree
        )
        TH = ufl.MixedElement([P2, P1])
        W = fem.FunctionSpace(domain, TH)

        # Trial and test functions
        (u, p) = ufl.TrialFunctions(W)
        (v, q) = ufl.TestFunctions(W)

        return W, u, p, v, q

    def _setup_boundary_conditions(self, task_config: TaskConfig, W, domain):
        """Set up boundary conditions based on task configuration."""
        bcs = []
        boundary_conditions = task_config.boundary_conditions
        geometry_type = task_config.geometry_type

        # Helper function to create boundary markers
        def create_boundary_function(condition_func):
            def boundary_func(x):
                return condition_func(x)

            return boundary_func

        # No-slip walls (common to all geometries)
        if "walls" in boundary_conditions:
            wall_bc = boundary_conditions["walls"]
            if wall_bc["type"] == "dirichlet":
                wall_value = wall_bc["value"]

                if geometry_type == "channel":
                    # Top and bottom walls
                    def walls(x):
                        width = task_config.geometry_params.get("width", 1.0)
                        return np.isclose(x[1], 0.0) | np.isclose(x[1], width)

                elif geometry_type == "cavity":
                    # Bottom, left, and right walls (lid is separate)
                    def walls(x):
                        length = task_config.geometry_params.get("length", 1.0)
                        width = task_config.geometry_params.get("width", 1.0)
                        return (
                            np.isclose(x[1], 0.0)
                            | np.isclose(x[0], 0.0)
                            | np.isclose(x[0], length)
                        )

                else:
                    # Default walls for other geometries
                    def walls(x):
                        return np.isclose(x[1], 0.0) | np.isclose(x[1], 1.0)

                walls_dofs = fem.locate_dofs_geometrical(W.sub(0), walls)
                wall_velocity = np.array(wall_value, dtype=PETSc.ScalarType)
                bc_walls = fem.dirichletbc(wall_velocity, walls_dofs, W.sub(0))
                bcs.append(bc_walls)

        # Inlet boundary conditions
        if "inlet" in boundary_conditions:
            inlet_bc = boundary_conditions["inlet"]
            if inlet_bc["type"] == "dirichlet":
                inlet_value = inlet_bc["value"]

                def inlet(x):
                    return np.isclose(x[0], 0.0)

                try:
                    inlet_dofs = fem.locate_dofs_geometrical(W.sub(0), inlet)

                    if len(inlet_dofs) > 0:
                        # Create inlet profile based on geometry
                        if geometry_type == "channel":
                            inlet_profile = task_config.geometry_params.get(
                                "inlet_profile", "parabolic"
                            )

                            if inlet_profile == "parabolic":
                                # Parabolic inlet profile: u(y) = 4*u_max*y*(H-y)/H^2
                                width = task_config.geometry_params.get("width", 1.0)
                                u_max = (
                                    inlet_value[0]
                                    if isinstance(inlet_value, (list, tuple))
                                    else inlet_value
                                )

                                def inlet_expr(x):
                                    y_rel = x[1] / width
                                    # Ensure y_rel is in [0, 1]
                                    y_rel = np.clip(y_rel, 0.0, 1.0)
                                    u_inlet = 4 * u_max * y_rel * (1 - y_rel)
                                    return np.stack((u_inlet, np.zeros_like(y_rel)))

                            elif inlet_profile == "plug":
                                # Plug flow profile with smooth transition near walls
                                width = task_config.geometry_params.get("width", 1.0)
                                u_max = (
                                    inlet_value[0]
                                    if isinstance(inlet_value, (list, tuple))
                                    else inlet_value
                                )
                                transition_width = 0.1 * width  # 10% of channel width

                                def inlet_expr(x):
                                    y = x[1]
                                    # Smooth transition using tanh
                                    u_inlet = (
                                        u_max
                                        * (
                                            np.tanh(
                                                (y - transition_width)
                                                / (0.1 * transition_width)
                                            )
                                            - np.tanh(
                                                (y - width + transition_width)
                                                / (0.1 * transition_width)
                                            )
                                        )
                                        / 2
                                    )
                                    u_inlet = np.maximum(u_inlet, 0.0)
                                    return np.stack((u_inlet, np.zeros_like(y)))

                            elif inlet_profile == "uniform":
                                # Uniform inlet profile
                                def inlet_expr(x):
                                    u_inlet = np.full_like(
                                        x[0],
                                        (
                                            inlet_value[0]
                                            if isinstance(inlet_value, (list, tuple))
                                            else inlet_value
                                        ),
                                    )
                                    v_inlet = np.full_like(
                                        x[0],
                                        (
                                            inlet_value[1]
                                            if isinstance(inlet_value, (list, tuple))
                                            and len(inlet_value) > 1
                                            else 0.0
                                        ),
                                    )
                                    return np.stack((u_inlet, v_inlet))

                            else:
                                # Default uniform profile
                                def inlet_expr(x):
                                    u_inlet = np.full_like(
                                        x[0],
                                        (
                                            inlet_value[0]
                                            if isinstance(inlet_value, (list, tuple))
                                            else inlet_value
                                        ),
                                    )
                                    v_inlet = np.full_like(
                                        x[0],
                                        (
                                            inlet_value[1]
                                            if isinstance(inlet_value, (list, tuple))
                                            and len(inlet_value) > 1
                                            else 0.0
                                        ),
                                    )
                                    return np.stack((u_inlet, v_inlet))

                        else:
                            # Default uniform inlet for other geometries
                            def inlet_expr(x):
                                u_inlet = np.full_like(
                                    x[0],
                                    (
                                        inlet_value[0]
                                        if isinstance(inlet_value, (list, tuple))
                                        else inlet_value
                                    ),
                                )
                                v_inlet = np.full_like(
                                    x[0],
                                    (
                                        inlet_value[1]
                                        if isinstance(inlet_value, (list, tuple))
                                        and len(inlet_value) > 1
                                        else 0.0
                                    ),
                                )
                                return np.stack((u_inlet, v_inlet))

                        inlet_function = fem.Function(W.sub(0).collapse()[0])
                        inlet_function.interpolate(inlet_expr)
                        bc_inlet = fem.dirichletbc(inlet_function, inlet_dofs, W.sub(0))
                        bcs.append(bc_inlet)

                except Exception as e:
                    logger.warning(f"Failed to apply inlet boundary condition: {e}")

            elif inlet_bc["type"] == "neumann":
                # Neumann boundary conditions would be handled in the variational form
                # For now, we skip them as they require modification of the weak form
                logger.warning(
                    "Neumann inlet boundary conditions not fully implemented"
                )

        # Lid boundary condition (for cavity flow)
        if "lid" in boundary_conditions:
            lid_bc = boundary_conditions["lid"]
            if lid_bc["type"] == "dirichlet":
                lid_value = lid_bc["value"]

                def lid(x):
                    width = task_config.geometry_params.get("width", 1.0)
                    return np.isclose(x[1], width)

                lid_dofs = fem.locate_dofs_geometrical(W.sub(0), lid)
                lid_velocity = np.array(lid_value, dtype=PETSc.ScalarType)
                bc_lid = fem.dirichletbc(lid_velocity, lid_dofs, W.sub(0))
                bcs.append(bc_lid)

        # Cylinder boundary condition
        if "cylinder" in boundary_conditions:
            cylinder_bc = boundary_conditions["cylinder"]
            if cylinder_bc["type"] == "dirichlet":
                cylinder_value = cylinder_bc["value"]

                # For simplified implementation, treat as additional walls
                # In full implementation, would use proper cylinder geometry
                cylinder_pos = task_config.geometry_params.get(
                    "cylinder_position", [0.5, 0.5]
                )
                cylinder_radius = task_config.geometry_params.get(
                    "cylinder_radius", 0.1
                )

                def cylinder_boundary(x):
                    # Approximate cylinder as points within radius
                    dist = np.sqrt(
                        (x[0] - cylinder_pos[0]) ** 2 + (x[1] - cylinder_pos[1]) ** 2
                    )
                    return (
                        dist <= cylinder_radius * 1.1
                    )  # Slightly larger for mesh points

                try:
                    cylinder_dofs = fem.locate_dofs_geometrical(
                        W.sub(0), cylinder_boundary
                    )
                    if len(cylinder_dofs) > 0:
                        cylinder_velocity = np.array(
                            cylinder_value, dtype=PETSc.ScalarType
                        )
                        bc_cylinder = fem.dirichletbc(
                            cylinder_velocity, cylinder_dofs, W.sub(0)
                        )
                        bcs.append(bc_cylinder)
                except:
                    # Skip cylinder BC if no points found (mesh too coarse)
                    logger.warning(
                        "Could not apply cylinder boundary condition - mesh may be too coarse"
                    )

        return bcs

    def _create_viscosity_function(self, task_config: TaskConfig, domain):
        """Create viscosity function based on task configuration."""
        viscosity_params = task_config.viscosity_params
        task_type = task_config.task_type

        # Get spatial coordinates
        x = ufl.SpatialCoordinate(domain)

        # Base viscosity
        mu_0 = viscosity_params.get("base_viscosity", 0.01)

        if task_type == "linear_viscosity":
            # Linear viscosity: mu(x,y) = mu_0 + grad_x*x + grad_y*y
            grad_x = viscosity_params.get("gradient_x", 0.0)
            grad_y = viscosity_params.get("gradient_y", 0.0)
            viscosity_expr = mu_0 + grad_x * x[0] + grad_y * x[1]

        elif task_type == "bilinear_viscosity":
            # Bilinear viscosity: mu(x,y) = mu_0 + grad_x*x + grad_y*y + cross_term*x*y
            grad_x = viscosity_params.get("gradient_x", 0.0)
            grad_y = viscosity_params.get("gradient_y", 0.0)
            cross_term = viscosity_params.get("cross_term", 0.0)
            viscosity_expr = (
                mu_0 + grad_x * x[0] + grad_y * x[1] + cross_term * x[0] * x[1]
            )

        elif task_type == "exponential_viscosity":
            # Exponential viscosity: mu(x,y) = mu_0 * amplitude * exp(decay_rate_x*x + decay_rate_y*y)
            decay_rate_x = viscosity_params.get("decay_rate_x", 0.0)
            decay_rate_y = viscosity_params.get("decay_rate_y", 1.0)
            amplitude = viscosity_params.get("amplitude", 1.0)

            # Clamp decay rates to prevent numerical issues
            decay_rate_x = max(min(decay_rate_x, 5.0), -5.0)
            decay_rate_y = max(min(decay_rate_y, 5.0), -5.0)

            viscosity_expr = (
                mu_0 * amplitude * ufl.exp(decay_rate_x * x[0] + decay_rate_y * x[1])
            )

        elif task_type == "temperature_dependent":
            # Temperature-dependent viscosity using Arrhenius-like relation
            ref_temp = viscosity_params.get("reference_temperature", 300.0)
            activation_energy = viscosity_params.get("activation_energy", 1000.0)
            temp_gradient = viscosity_params.get("temperature_gradient", 0.0)

            # Linear temperature variation with bounds
            temperature = ref_temp + temp_gradient * x[1]
            temperature = ufl.max_value(temperature, 200.0)  # Minimum temperature
            temperature = ufl.min_value(temperature, 500.0)  # Maximum temperature

            # Arrhenius-like relation: mu = mu_0 * exp(E_a / (R * T))
            # Simplified: mu = mu_0 * exp(activation_energy / temperature / ref_temp)
            viscosity_expr = mu_0 * ufl.exp(activation_energy / temperature / ref_temp)

        elif task_type == "non_newtonian":
            # Non-Newtonian viscosity (power-law model, simplified)
            consistency_index = viscosity_params.get("consistency_index", 0.1)
            flow_behavior_index = viscosity_params.get("flow_behavior_index", 1.0)
            yield_stress = viscosity_params.get("yield_stress", 0.0)

            # For simplicity, use spatially varying viscosity based on position
            # In full implementation, this would depend on strain rate
            shear_rate_approx = (
                ufl.sqrt(x[0] ** 2 + x[1] ** 2) + 1e-6
            )  # Approximate shear rate

            if abs(flow_behavior_index - 1.0) < 1e-6:
                # Newtonian case
                viscosity_expr = mu_0 + consistency_index
            else:
                # Power-law: mu_eff = K * (gamma_dot)^(n-1) + mu_0
                viscosity_expr = mu_0 + consistency_index * ufl.pow(
                    shear_rate_approx, flow_behavior_index - 1.0
                )

        elif task_type == "polynomial_viscosity":
            # Polynomial viscosity: mu(x,y) = mu_0 + sum(c_ij * x^i * y^j)
            coeffs = viscosity_params.get("polynomial_coeffs", {})
            viscosity_expr = mu_0

            for key, coeff in coeffs.items():
                if "_" in key:  # Format: 'x2_y1' for x^2 * y^1
                    parts = key.split("_")
                    x_power = int(parts[0][1:]) if len(parts[0]) > 1 else 1
                    y_power = int(parts[1][1:]) if len(parts[1]) > 1 else 1
                    viscosity_expr += (
                        coeff * ufl.pow(x[0], x_power) * ufl.pow(x[1], y_power)
                    )

        elif task_type == "sinusoidal_viscosity":
            # Sinusoidal viscosity: mu(x,y) = mu_0 + amplitude * sin(freq_x*x + freq_y*y + phase)
            amplitude = viscosity_params.get("amplitude", 0.01)
            freq_x = viscosity_params.get("frequency_x", 2.0)
            freq_y = viscosity_params.get("frequency_y", 2.0)
            phase = viscosity_params.get("phase", 0.0)

            viscosity_expr = mu_0 + amplitude * ufl.sin(
                freq_x * x[0] + freq_y * x[1] + phase
            )

        else:
            # Default constant viscosity
            viscosity_expr = mu_0

        # Ensure viscosity is positive and bounded
        min_viscosity = max(mu_0 * 0.1, 1e-6)  # At least 10% of base viscosity
        max_viscosity = mu_0 * 100.0  # At most 100x base viscosity

        viscosity_expr = ufl.max_value(viscosity_expr, min_viscosity)
        viscosity_expr = ufl.min_value(viscosity_expr, max_viscosity)

        return viscosity_expr

    def _setup_variational_problem(
        self, task_config: TaskConfig, u, p, v, q, viscosity_expr, domain
    ):
        """Set up the variational formulation of the problem."""
        reynolds = task_config.reynolds_number

        if reynolds > 100:
            # Navier-Stokes equations (nonlinear)
            # This is a simplified linearization - full implementation would use Newton's method
            F = (
                (1 / reynolds)
                * ufl.inner(viscosity_expr * ufl.grad(u), ufl.grad(v))
                * ufl.dx
            )
            F += ufl.inner(ufl.grad(u) * u, v) * ufl.dx  # Convection term (linearized)
            F -= ufl.inner(p, ufl.div(v)) * ufl.dx
            F += ufl.inner(ufl.div(u), q) * ufl.dx
        else:
            # Stokes equations (linear)
            F = ufl.inner(viscosity_expr * ufl.grad(u), ufl.grad(v)) * ufl.dx
            F -= ufl.inner(p, ufl.div(v)) * ufl.dx
            F += ufl.inner(ufl.div(u), q) * ufl.dx

        # Add stabilization if requested
        if self.solver_config.use_stabilization:
            h = ufl.CellDiameter(domain)
            tau = h**2 / (4 * viscosity_expr)  # Stabilization parameter
            F += tau * ufl.inner(ufl.grad(p), ufl.grad(q)) * ufl.dx

        return F

    def _solve_problem(self, F, bcs, W):
        """Solve the variational problem."""
        # Convert to linear system
        a, L = ufl.lhs(F), ufl.rhs(F)

        # Create solution function
        w = fem.Function(W)

        # Set up and solve the problem
        problem = fem.petsc.LinearProblem(
            a,
            L,
            bcs=bcs,
            u=w,
            petsc_options={
                "ksp_type": (
                    "preonly" if self.solver_config.solver_type == "direct" else "gmres"
                ),
                "pc_type": (
                    "lu" if self.solver_config.solver_type == "direct" else "ilu"
                ),
                "ksp_rtol": self.solver_config.tolerance,
                "ksp_max_it": self.solver_config.max_iterations,
            },
        )

        try:
            problem.solve()
            logger.debug("FEniCSx problem solved successfully")
        except Exception as e:
            logger.error(f"FEniCSx solver failed: {e}")
            raise

        return w

    def _evaluate_solution(
        self, w, coordinates: torch.Tensor, task_config: TaskConfig
    ) -> AnalyticalSolution:
        """Evaluate the solution at specified coordinates."""
        # Extract velocity and pressure
        u_sol, p_sol = w.split()

        # Convert coordinates to numpy
        coords_np = coordinates.cpu().numpy()

        # Prepare evaluation points (FEniCSx expects 3D points)
        if coords_np.shape[1] == 2:
            points = np.column_stack([coords_np, np.zeros(len(coords_np))])
        else:
            points = coords_np

        try:
            # Evaluate velocity and pressure
            u_values = u_sol.eval(points, np.arange(len(points)))
            p_values = p_sol.eval(points, np.arange(len(points)))

            # Extract velocity components
            velocity = torch.from_numpy(u_values[:, :2]).float()
            pressure = torch.from_numpy(p_values.reshape(-1, 1)).float()

            # Evaluate viscosity field at coordinates
            viscosity_field = self._evaluate_viscosity_field(coordinates, task_config)

        except Exception as e:
            logger.warning(
                f"Failed to evaluate FEniCSx solution: {e}. Using fallback values."
            )
            # Fallback to zeros if evaluation fails
            velocity = torch.zeros(len(coordinates), 2)
            pressure = torch.zeros(len(coordinates), 1)
            viscosity_field = torch.full(
                (len(coordinates), 1),
                task_config.viscosity_params.get("base_viscosity", 0.01),
            )

        return AnalyticalSolution(
            velocity=velocity,
            pressure=pressure,
            coordinates=coordinates,
            viscosity_field=viscosity_field,
            metadata={
                "solution_type": "fenicsx_solution",
                "task_id": task_config.task_id,
                "reynolds_number": task_config.reynolds_number,
                "mesh_resolution": self.solver_config.mesh_resolution,
                "solver_type": self.solver_config.solver_type,
            },
        )

    def _evaluate_viscosity_field(
        self, coordinates: torch.Tensor, task_config: TaskConfig
    ) -> torch.Tensor:
        """Evaluate viscosity field at given coordinates."""
        coords_np = coordinates.cpu().numpy()
        x, y = coords_np[:, 0], coords_np[:, 1]

        viscosity_params = task_config.viscosity_params
        task_type = task_config.task_type

        mu_0 = viscosity_params.get("base_viscosity", 0.01)

        if task_type == "linear_viscosity":
            grad_x = viscosity_params.get("gradient_x", 0.0)
            grad_y = viscosity_params.get("gradient_y", 0.0)
            viscosity = mu_0 + grad_x * x + grad_y * y

        elif task_type == "bilinear_viscosity":
            grad_x = viscosity_params.get("gradient_x", 0.0)
            grad_y = viscosity_params.get("gradient_y", 0.0)
            cross_term = viscosity_params.get("cross_term", 0.0)
            viscosity = mu_0 + grad_x * x + grad_y * y + cross_term * x * y

        elif task_type == "exponential_viscosity":
            decay_rate_x = viscosity_params.get("decay_rate_x", 0.0)
            decay_rate_y = viscosity_params.get("decay_rate_y", 1.0)
            amplitude = viscosity_params.get("amplitude", 1.0)
            viscosity = mu_0 * amplitude * np.exp(decay_rate_x * x + decay_rate_y * y)

        else:
            viscosity = np.full_like(x, mu_0)

        # Ensure positive viscosity
        viscosity = np.maximum(viscosity, 1e-6)

        return torch.from_numpy(viscosity.reshape(-1, 1)).float()

    def validate_against_analytical(
        self,
        task_config: TaskConfig,
        coordinates: torch.Tensor,
        analytical_solution: AnalyticalSolution,
    ) -> Dict[str, float]:
        """
        Validate FEniCSx solution against analytical solution.

        Args:
            task_config: Task configuration
            coordinates: Evaluation coordinates
            analytical_solution: Analytical solution for comparison

        Returns:
            Dictionary of validation metrics
        """
        # Solve with FEniCSx
        fenicsx_solution = self.solve_task(task_config, coordinates)

        # Compute differences
        velocity_diff = torch.norm(
            fenicsx_solution.velocity - analytical_solution.velocity, dim=1
        )
        pressure_diff = torch.abs(
            fenicsx_solution.pressure - analytical_solution.pressure
        ).squeeze()

        # Compute metrics
        metrics = {
            "velocity_l2_error": torch.mean(velocity_diff).item(),
            "velocity_max_error": torch.max(velocity_diff).item(),
            "pressure_l2_error": torch.mean(pressure_diff).item(),
            "pressure_max_error": torch.max(pressure_diff).item(),
            "relative_velocity_error": (
                torch.mean(velocity_diff)
                / torch.mean(torch.norm(analytical_solution.velocity, dim=1))
            ).item(),
            "relative_pressure_error": (
                torch.mean(pressure_diff)
                / torch.mean(torch.abs(analytical_solution.pressure))
            ).item(),
        }

        return metrics

    def _validate_task_config(self, task_config: TaskConfig):
        """Validate task configuration before solving."""
        # Check Reynolds number bounds
        if not (0.1 <= task_config.reynolds_number <= 10000.0):
            raise ValueError(
                f"Reynolds number {task_config.reynolds_number} outside valid range [0.1, 10000]"
            )

        # Check viscosity parameters
        base_visc = task_config.viscosity_params.get("base_viscosity", 0.01)
        if not (1e-6 <= base_visc <= 1e3):
            raise ValueError(
                f"Base viscosity {base_visc} outside physical bounds [1e-6, 1e3]"
            )

        # Check geometry parameters
        if task_config.geometry_type not in ["channel", "cavity", "cylinder"]:
            raise ValueError(f"Unsupported geometry type: {task_config.geometry_type}")

        # Validate geometry dimensions
        if task_config.geometry_type in ["channel", "cavity"]:
            length = task_config.geometry_params.get("length", 1.0)
            width = task_config.geometry_params.get("width", 1.0)
            if length <= 0 or width <= 0:
                raise ValueError("Geometry dimensions must be positive")

    def _validate_solution_quality(
        self, solution: AnalyticalSolution, task_config: TaskConfig
    ):
        """Validate solution quality and physics consistency."""
        # Check for NaN or infinite values
        if torch.any(torch.isnan(solution.velocity)) or torch.any(
            torch.isinf(solution.velocity)
        ):
            raise ValueError("Solution contains NaN or infinite velocity values")

        if torch.any(torch.isnan(solution.pressure)) or torch.any(
            torch.isinf(solution.pressure)
        ):
            raise ValueError("Solution contains NaN or infinite pressure values")

        # Check velocity magnitude bounds
        velocity_magnitude = torch.norm(solution.velocity, dim=1)
        max_velocity = torch.max(velocity_magnitude).item()

        # Reasonable velocity bounds based on Reynolds number
        expected_max_velocity = task_config.reynolds_number * 0.1  # Heuristic bound
        if max_velocity > expected_max_velocity * 10:
            logger.warning(f"Velocity magnitude {max_velocity} seems unreasonably high")

        # Check pressure bounds
        pressure_range = torch.max(solution.pressure) - torch.min(solution.pressure)
        if pressure_range.item() > 1e6:
            logger.warning(
                f"Pressure range {pressure_range.item()} seems unreasonably large"
            )

    def _create_fallback_solution(
        self, coordinates: torch.Tensor, task_config: TaskConfig, error_msg: str
    ) -> AnalyticalSolution:
        """Create fallback solution when FEniCSx solver fails."""
        logger.warning(f"Creating fallback solution due to error: {error_msg}")

        # Create zero solution
        velocity = torch.zeros(len(coordinates), 2)
        pressure = torch.zeros(len(coordinates), 1)

        # Set reasonable viscosity field
        base_viscosity = task_config.viscosity_params.get("base_viscosity", 0.01)
        viscosity_field = torch.full((len(coordinates), 1), base_viscosity)

        return AnalyticalSolution(
            velocity=velocity,
            pressure=pressure,
            coordinates=coordinates,
            viscosity_field=viscosity_field,
            metadata={
                "solution_type": "fenicsx_fallback",
                "task_id": task_config.task_id,
                "error_message": error_msg,
                "fallback_reason": "solver_failure",
            },
        )

    def solve_task_batch(
        self, task_configs: List[TaskConfig], coordinates: torch.Tensor
    ) -> List[AnalyticalSolution]:
        """
        Solve multiple tasks efficiently.

        Args:
            task_configs: List of task configurations
            coordinates: Coordinate points (same for all tasks)

        Returns:
            List of AnalyticalSolution objects
        """
        solutions = []

        for i, task_config in enumerate(task_configs):
            logger.debug(
                f"Solving task {i+1}/{len(task_configs)}: {task_config.task_id}"
            )

            try:
                solution = self.solve_task(task_config, coordinates)
                solutions.append(solution)
            except Exception as e:
                logger.error(f"Failed to solve task {task_config.task_id}: {e}")
                fallback_solution = self._create_fallback_solution(
                    coordinates, task_config, str(e)
                )
                solutions.append(fallback_solution)

        return solutions

    def generate_ground_truth_dataset(
        self,
        task_configs: List[TaskConfig],
        n_points_per_task: int = 1000,
        save_path: Optional[str] = None,
    ) -> Dict[str, Any]:
        """
        Generate ground truth dataset for multiple tasks.

        Args:
            task_configs: List of task configurations
            n_points_per_task: Number of evaluation points per task
            save_path: Optional path to save the dataset

        Returns:
            Dictionary containing the generated dataset
        """
        logger.info(f"Generating ground truth dataset for {len(task_configs)} tasks")

        dataset = {
            "tasks": [],
            "metadata": {
                "n_tasks": len(task_configs),
                "n_points_per_task": n_points_per_task,
                "solver_config": self.solver_config.__dict__,
                "generation_timestamp": str(np.datetime64("now")),
            },
        }

        for i, task_config in enumerate(task_configs):
            logger.debug(f"Processing task {i+1}/{len(task_configs)}")

            # Generate evaluation coordinates for this task
            coordinates = self._generate_evaluation_coordinates(
                task_config, n_points_per_task
            )

            # Solve the task
            solution = self.solve_task(task_config, coordinates)

            # Store task data
            task_data = {
                "task_config": task_config.to_dict(),
                "coordinates": coordinates.numpy(),
                "velocity": solution.velocity.numpy(),
                "pressure": solution.pressure.numpy(),
                "viscosity_field": (
                    solution.viscosity_field.numpy()
                    if solution.viscosity_field is not None
                    else None
                ),
                "metadata": solution.metadata,
            }

            dataset["tasks"].append(task_data)

        # Save dataset if path provided
        if save_path:
            self._save_dataset(dataset, save_path)

        logger.info(
            f"Generated ground truth dataset with {len(dataset['tasks'])} tasks"
        )
        return dataset

    def _generate_evaluation_coordinates(
        self, task_config: TaskConfig, n_points: int
    ) -> torch.Tensor:
        """Generate evaluation coordinates for a task."""
        # Get domain bounds from geometry
        if task_config.geometry_type == "channel":
            length = task_config.geometry_params.get("length", 1.0)
            width = task_config.geometry_params.get("width", 1.0)
            x_bounds = (0.0, length)
            y_bounds = (0.0, width)

        elif task_config.geometry_type == "cavity":
            length = task_config.geometry_params.get("length", 1.0)
            width = task_config.geometry_params.get("width", 1.0)
            x_bounds = (0.0, length)
            y_bounds = (0.0, width)

        elif task_config.geometry_type == "cylinder":
            domain_length = task_config.geometry_params.get("domain_length", 2.0)
            domain_width = task_config.geometry_params.get("domain_width", 1.0)
            x_bounds = (0.0, domain_length)
            y_bounds = (0.0, domain_width)

        else:
            # Default bounds
            x_bounds = (0.0, 1.0)
            y_bounds = (0.0, 1.0)

        # Generate coordinates with mixed sampling strategy
        n_interior = int(0.8 * n_points)
        n_boundary = n_points - n_interior

        # Interior points (uniform random)
        x_interior = np.random.uniform(
            x_bounds[0] + 0.01, x_bounds[1] - 0.01, n_interior
        )
        y_interior = np.random.uniform(
            y_bounds[0] + 0.01, y_bounds[1] - 0.01, n_interior
        )

        # Boundary points
        n_per_boundary = n_boundary // 4

        # Bottom boundary
        x_bottom = np.random.uniform(x_bounds[0], x_bounds[1], n_per_boundary)
        y_bottom = np.full(n_per_boundary, y_bounds[0])

        # Top boundary
        x_top = np.random.uniform(x_bounds[0], x_bounds[1], n_per_boundary)
        y_top = np.full(n_per_boundary, y_bounds[1])

        # Left boundary
        x_left = np.full(n_per_boundary, x_bounds[0])
        y_left = np.random.uniform(y_bounds[0], y_bounds[1], n_per_boundary)

        # Right boundary
        x_right = np.full(n_boundary - 3 * n_per_boundary, x_bounds[1])
        y_right = np.random.uniform(
            y_bounds[0], y_bounds[1], n_boundary - 3 * n_per_boundary
        )

        # Combine all coordinates
        x_all = np.concatenate([x_interior, x_bottom, x_top, x_left, x_right])
        y_all = np.concatenate([y_interior, y_bottom, y_top, y_left, y_right])

        coordinates = np.stack([x_all, y_all], axis=1)

        return torch.from_numpy(coordinates).float()

    def _save_dataset(self, dataset: Dict[str, Any], save_path: str):
        """Save dataset to file."""
        import json
        from pathlib import Path

        save_path = Path(save_path)
        save_path.parent.mkdir(parents=True, exist_ok=True)

        if save_path.suffix == ".json":
            # Convert numpy arrays to lists for JSON serialization
            json_dataset = self._convert_dataset_for_json(dataset)
            with open(save_path, "w") as f:
                json.dump(json_dataset, f, indent=2)

        elif save_path.suffix in [".npz", ".npy"]:
            # Save as numpy archive
            np.savez_compressed(save_path, **dataset)

        else:
            # Default to pickle
            import pickle

            with open(save_path, "wb") as f:
                pickle.dump(dataset, f)

        logger.info(f"Saved dataset to {save_path}")

    def _convert_dataset_for_json(self, dataset: Dict[str, Any]) -> Dict[str, Any]:
        """Convert dataset with numpy arrays to JSON-serializable format."""
        json_dataset = {"metadata": dataset["metadata"], "tasks": []}

        for task_data in dataset["tasks"]:
            json_task = {
                "task_config": task_data["task_config"],
                "coordinates": task_data["coordinates"].tolist(),
                "velocity": task_data["velocity"].tolist(),
                "pressure": task_data["pressure"].tolist(),
                "viscosity_field": (
                    task_data["viscosity_field"].tolist()
                    if task_data["viscosity_field"] is not None
                    else None
                ),
                "metadata": task_data["metadata"],
            }
            json_dataset["tasks"].append(json_task)

        return json_dataset


def create_fenicsx_solver(
    solver_config: Optional[SolverConfig] = None,
) -> Optional[FEniCSxSolver]:
    """
    Factory function to create FEniCSx solver if available.

    Args:
        solver_config: Optional solver configuration

    Returns:
        FEniCSxSolver instance if FEniCSx is available, None otherwise
    """
    if not FENICSX_AVAILABLE:
        logger.warning("FEniCSx not available, returning None")
        return None

    return FEniCSxSolver(solver_config)
